{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59a10435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy import integrate\n",
    "from scipy import linalg\n",
    "from scipy import interpolate\n",
    "from sklearn import gaussian_process as gp\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "import operator\n",
    "from functools import reduce\n",
    "from functools import partial\n",
    "from timeit import default_timer\n",
    "from utilities3 import *\n",
    "from Adam import Adam\n",
    "from deeponet import *\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f965aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_train = generate(length_scale=0.2,out_dim=201)\n",
    "f_0 = np.zeros_like(f_train)+1\n",
    "f_test_1 = generate(samples=100,length_scale=0.2,out_dim=201)\n",
    "f_test_2 = generate(samples=100,length_scale=2,out_dim=201)\n",
    "f_test_3 = generate(samples=100,length_scale=0.2,A=10,out_dim=201)\n",
    "f_test_4 = generate(samples=100,length_scale=2,A=10,out_dim=201)\n",
    "f_test = np.concatenate((f_test_1,f_test_2))\n",
    "f_test = np.concatenate((f_test,f_test_3))\n",
    "f_test = np.concatenate((f_test,f_test_4))\n",
    "u_0 = RK4(0,f_0)\n",
    "u_train = RK4(0,f_train)\n",
    "u_test = RK4(0,f_test)\n",
    "f_new = 1*f_train+10\n",
    "u_new = 1*u_train+10*u_0\n",
    "f_aug = np.concatenate((f_train,f_new))\n",
    "u_aug = np.concatenate((u_train,u_new))\n",
    "\n",
    "dim = f_train.shape[-1]\n",
    "f_train = np.delete(f_train,np.linspace(1,dim-2,(dim-1)//2).astype(np.int32).tolist(),-1)\n",
    "f_test = np.delete(f_test,np.linspace(1,dim-2,(dim-1)//2).astype(np.int32).tolist(),-1)\n",
    "f_0 = np.delete(f_0,np.linspace(1,dim-2,(dim-1)//2).astype(np.int32).tolist(),-1)\n",
    "f_aug = np.delete(f_aug,np.linspace(1,dim-2,(dim-1)//2).astype(np.int32).tolist(),-1)\n",
    "dim = (dim-1)//2+1\n",
    "grid = np.linspace(0, 1, dim)\n",
    "\n",
    "N = f_train.shape[0]\n",
    "loc = np.zeros((N,1))\n",
    "res = np.zeros((N,1))\n",
    "for i in range(N):\n",
    "    j = np.random.randint(dim)\n",
    "    loc[i,0] = grid[j]\n",
    "    res[i,0] = u_train[i,j]\n",
    "    \n",
    "f_train = torch.Tensor(f_train)\n",
    "loc_train = torch.Tensor(loc)\n",
    "u_train = torch.Tensor(res)    \n",
    "train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(f_train, loc_train, u_train), batch_size=100, shuffle=True)\n",
    "\n",
    "N = f_aug.shape[0]\n",
    "loc = np.zeros((N,1))\n",
    "res = np.zeros((N,1))\n",
    "for i in range(N):\n",
    "    j = np.random.randint(dim)\n",
    "    loc[i,0] = grid[j]\n",
    "    res[i,0] = u_aug[i,j]\n",
    "\n",
    "f_aug = torch.Tensor(f_aug)\n",
    "loc_aug = torch.Tensor(loc)\n",
    "u_aug = torch.Tensor(res)\n",
    "aug_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(f_aug, loc_aug, u_aug), batch_size=100, shuffle=True)\n",
    "\n",
    "dim = f_test.shape[-1]\n",
    "N = f_test.shape[0]*dim\n",
    "loc = np.zeros((N,1))\n",
    "res = np.zeros((N,1))\n",
    "f = np.zeros((N,dim))\n",
    "for i in range(N):\n",
    "    f[i] = f_test[i//dim]\n",
    "    loc[i,0] = grid[i%dim]\n",
    "    res[i,0] = u_test[i//dim,i%dim]\n",
    "f_test = torch.Tensor(f)\n",
    "loc = torch.Tensor(loc)\n",
    "res = torch.Tensor(res)\n",
    "test_1_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(f_test[:100*dim], loc[:100*dim], res[:100*dim]), batch_size=dim, shuffle=False)\n",
    "test_2_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(f_test[100*dim:200*dim], loc[100*dim:200*dim], res[100*dim:200*dim]), batch_size=dim, shuffle=False)\n",
    "test_3_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(f_test[200*dim:300*dim], loc[200*dim:300*dim], res[200*dim:300*dim]), batch_size=dim, shuffle=False)\n",
    "test_4_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(f_test[300*dim:], loc[300*dim:], res[300*dim:]), batch_size=dim, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a16c7937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 600/600 MSE = 0.0002080001\n",
      "\n",
      "test error: L2 =  0.0800523404404521 MSE = 0.00046542880951164987\n",
      "test error: L2 =  0.029499691808596254 MSE = 6.317070073464493e-05\n",
      "test error: L2 =  0.010337527561932802 MSE = 0.0036719632521271706\n",
      "test error: L2 =  0.009888848261907697 MSE = 0.0032209656154736878\n"
     ]
    }
   ],
   "source": [
    "ntrain = 1000\n",
    "ntest = 100\n",
    "naug = 2000\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "epochs = 600\n",
    "step_size = 50\n",
    "gamma = 0.5\n",
    "\n",
    "model = DeepONet(dim,1).cuda()\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "for ep in range(epochs):\n",
    "    model.train()\n",
    "    train_mse = 0\n",
    "    for x, l, y in train_loader:\n",
    "        x, l, y = x.cuda(), l.cuda(), y.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x,l)\n",
    "        mse = F.mse_loss(out.view(batch_size, -1), y.view(batch_size, -1), reduction='mean')\n",
    "        mse.backward()\n",
    "        optimizer.step()\n",
    "        train_mse += mse.item()\n",
    "    scheduler.step()\n",
    "    train_mse /= len(train_loader)\n",
    "    print('\\repoch {:d}/{:d} MSE = {:.10f}'.format(ep+1,epochs,train_mse), end='', flush=True)\n",
    "    \n",
    "print('\\n')\n",
    "myloss = LpLoss(size_average=False)\n",
    "test_mse = 0\n",
    "test_l2 = 0\n",
    "with torch.no_grad():\n",
    "    for x, l, y in test_1_loader:\n",
    "        x, l, y = x.cuda(), l.cuda(), y.cuda()\n",
    "        out = model(x,l).view(-1)\n",
    "        mse = F.mse_loss(out.view(1, -1), y.view(1, -1), reduction='mean')\n",
    "        l2 = myloss(out.view(1, -1), y.view(1, -1))\n",
    "        test_mse += mse.item()\n",
    "        test_l2 += l2.item()\n",
    "    test_mse /= len(test_1_loader)\n",
    "    test_l2 /= ntest\n",
    "    print('test error: L2 = ',test_l2,'MSE =',test_mse)\n",
    "\n",
    "\n",
    "test_mse = 0\n",
    "test_l2 = 0\n",
    "with torch.no_grad():\n",
    "    for x, l, y in test_2_loader:\n",
    "        x, l, y = x.cuda(), l.cuda(), y.cuda()\n",
    "        out = model(x,l).view(-1)\n",
    "        mse = F.mse_loss(out.view(1, -1), y.view(1, -1), reduction='mean')\n",
    "        l2 = myloss(out.view(1, -1), y.view(1, -1))\n",
    "        test_mse += mse.item()\n",
    "        test_l2 += l2.item()        \n",
    "    test_mse /= len(test_2_loader)\n",
    "    test_l2 /= ntest\n",
    "    print('test error: L2 = ',test_l2,'MSE =',test_mse)\n",
    "    \n",
    "\n",
    "test_mse = 0\n",
    "test_l2 = 0\n",
    "with torch.no_grad():\n",
    "    for x, l, y in test_3_loader:\n",
    "        x, l, y = x.cuda(), l.cuda(), y.cuda()\n",
    "        out = model(x,l).view(-1)\n",
    "        mse = F.mse_loss(out.view(1, -1), y.view(1, -1), reduction='mean')\n",
    "        l2 = myloss(out.view(1, -1), y.view(1, -1))\n",
    "        test_mse += mse.item()\n",
    "        test_l2 += l2.item()        \n",
    "    test_mse /= len(test_3_loader)\n",
    "    test_l2 /= ntest\n",
    "    print('test error: L2 = ',test_l2,'MSE =',test_mse)\n",
    "    \n",
    "test_mse = 0\n",
    "test_l2 = 0\n",
    "with torch.no_grad():\n",
    "    for x, l, y in test_4_loader:\n",
    "        x, l, y = x.cuda(), l.cuda(), y.cuda()\n",
    "        out = model(x,l).view(-1)\n",
    "        mse = F.mse_loss(out.view(1, -1), y.view(1, -1), reduction='mean')\n",
    "        l2 = myloss(out.view(1, -1), y.view(1, -1))\n",
    "        test_mse += mse.item()\n",
    "        test_l2 += l2.item()        \n",
    "    test_mse /= len(test_4_loader)\n",
    "    test_l2 /= ntest\n",
    "    print('test error: L2 = ',test_l2,'MSE =',test_mse)\n",
    "    \n",
    "torch.save(model,'model/deeponet1_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20c690ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 600/600 MSE = 0.0016342292\n",
      "\n",
      "test error: L2 =  0.15394851101562382 MSE = 0.0017653913095273311\n",
      "test error: L2 =  0.039863525858381765 MSE = 9.087708008223672e-05\n",
      "test error: L2 =  0.006955932239070535 MSE = 0.002058440062755835\n",
      "test error: L2 =  0.0013346756820101292 MSE = 5.8228449197486044e-05\n"
     ]
    }
   ],
   "source": [
    "model = DeepONet(dim,1).cuda()\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "for ep in range(epochs):\n",
    "    model.train()\n",
    "    train_mse = 0\n",
    "    for x, l, y in aug_loader:\n",
    "        x, l, y = x.cuda(), l.cuda(), y.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x,l)\n",
    "        mse = F.mse_loss(out.view(batch_size, -1), y.view(batch_size, -1), reduction='mean')\n",
    "        mse.backward()\n",
    "        optimizer.step()\n",
    "        train_mse += mse.item()\n",
    "    scheduler.step()\n",
    "    train_mse /= len(aug_loader)\n",
    "    print('\\repoch {:d}/{:d} MSE = {:.10f}'.format(ep+1,epochs,train_mse), end='', flush=True)\n",
    "    \n",
    "print('\\n')\n",
    "test_mse = 0\n",
    "test_l2 = 0\n",
    "with torch.no_grad():\n",
    "    for x, l, y in test_1_loader:\n",
    "        x, l, y = x.cuda(), l.cuda(), y.cuda()\n",
    "        out = model(x,l).view(-1)\n",
    "        mse = F.mse_loss(out.view(1, -1), y.view(1, -1), reduction='mean')\n",
    "        l2 = myloss(out.view(1, -1), y.view(1, -1))\n",
    "        test_mse += mse.item()\n",
    "        test_l2 += l2.item()\n",
    "    test_mse /= len(test_1_loader)\n",
    "    test_l2 /= ntest\n",
    "    print('test error: L2 = ',test_l2,'MSE =',test_mse)\n",
    "\n",
    "test_mse = 0\n",
    "test_l2 = 0\n",
    "with torch.no_grad():\n",
    "    for x, l, y in test_2_loader:\n",
    "        x, l, y = x.cuda(), l.cuda(), y.cuda()\n",
    "        out = model(x,l).view(-1)\n",
    "        mse = F.mse_loss(out.view(1, -1), y.view(1, -1), reduction='mean')\n",
    "        l2 = myloss(out.view(1, -1), y.view(1, -1))\n",
    "        test_mse += mse.item()\n",
    "        test_l2 += l2.item()\n",
    "    test_mse /= len(test_2_loader)\n",
    "    test_l2 /= ntest\n",
    "    print('test error: L2 = ',test_l2,'MSE =',test_mse)\n",
    "    \n",
    "test_mse = 0\n",
    "test_l2 = 0\n",
    "with torch.no_grad():\n",
    "    for x, l, y in test_3_loader:\n",
    "        x, l, y = x.cuda(), l.cuda(), y.cuda()\n",
    "        out = model(x,l).view(-1)\n",
    "        mse = F.mse_loss(out.view(1, -1), y.view(1, -1), reduction='mean')\n",
    "        l2 = myloss(out.view(1, -1), y.view(1, -1))\n",
    "        test_mse += mse.item()\n",
    "        test_l2 += l2.item()        \n",
    "    test_mse /= len(test_3_loader)\n",
    "    test_l2 /= ntest\n",
    "    print('test error: L2 = ',test_l2,'MSE =',test_mse)\n",
    "    \n",
    "\n",
    "test_mse = 0\n",
    "test_l2 = 0\n",
    "with torch.no_grad():\n",
    "    for x, l, y in test_4_loader:\n",
    "        x, l, y = x.cuda(), l.cuda(), y.cuda()\n",
    "        out = model(x,l).view(-1)\n",
    "        mse = F.mse_loss(out.view(1, -1), y.view(1, -1), reduction='mean')\n",
    "        l2 = myloss(out.view(1, -1), y.view(1, -1))\n",
    "        test_mse += mse.item()\n",
    "        test_l2 += l2.item()        \n",
    "    test_mse /= len(test_4_loader)\n",
    "    test_l2 /= ntest\n",
    "    print('test error: L2 = ',test_l2,'MSE =',test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7cc9c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,'model/deeponet1_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad77d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
